{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a1b13e68ce86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxarray\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as mp\n",
    "import numpy as np\n",
    "import metpy.calc as mpc\n",
    "import xarray as xr\n",
    "import datetime as dt\n",
    "\n",
    "##### SCAM FORCINGS GENERATION FOR SAS PARAMETERS IN #####\n",
    "### http://www2.mmm.ucar.edu/people/patton/documents/su_et_al.ACP.2016.pdf ###\n",
    "\n",
    "## Time ##\n",
    "\n",
    "bdate = 20130610\n",
    "\n",
    "spd = 86400 # Seconds per day\n",
    "mpd = 1440  # Mins per day\n",
    "spm = 60    # Seconds per minute.\n",
    "\n",
    "dtime = 1*spm    # Time interval (minutes*60=sec) for each time point on file (does not have to be DTIME)\n",
    "tperiod = (16.5-6)*sph    # Time length (hours*sph=sec) for whole of IOP\n",
    "iop_zstart = 12*sph  # 12Z = 6AM MST (US)\n",
    "\n",
    "iop_lat = 32.5 # Lat location (SAS average of two smapling sites)\n",
    "iop_lon = -87.15 # Lon\n",
    "\n",
    "lno_lsf = True # Set large scale forcings to zero.\n",
    "\n",
    "vdesc = ('Initial BL height', \\\n",
    "         'Subsidence rate', \\\n",
    "         'Surface sensible heat flux',\\\n",
    "         'Surface latent heat flux',\\\n",
    "         'Entrainment/surface heat flux ratio'\\\n",
    "         'Initial BL potential temperature',\\\n",
    "         'Initial FT potential temperature',\\\n",
    "         'Potential temperature lapse rate FT',\\\n",
    "         'Advection of potential temperature',\\\n",
    "         'Initial BL specific humidity',\\\n",
    "         'Initial FT specific humidity',\\\n",
    "         'Specific humidity lapse rate FT',\\\n",
    "         'Advection of specific humidity')\n",
    "\n",
    "\n",
    "vname = ('pblh','w_sub','shflx','lhflx','eratio','the_bl','the_trop','the_lr','the_adv','q_bl','q_trop','q_lr','q_adv')\n",
    "#vval =  (500,    9.e-6,   0.1,   0.15,    0.2,     296.6,   298.1,     0.003,   6.40e-4, 16.8,    12.8,   -0.004,   1.5e-4) # paper values\n",
    "vval =  (500,    9.e-6,   0.1,   0.15,    0.2,     296.6,   298.1,     0.003,   6.40e-4, 16.8,    12.8,   -0.004,   1.5e-4) # paper values\n",
    "\n",
    "\n",
    "##############################\n",
    "\n",
    "\n",
    "##### IOP file info. ######\n",
    "iop_file_in = './ARM95_4scam_c180703.nc'   # input template\n",
    "iop_file_out = './SAS_ideal_4scam_03.nc' # Output forcing file\n",
    "\n",
    "## Read in and IOP template\n",
    "iop_in = xr.open_dataset(iop_file_in,engine='netcdf4') # This is like addfile -> pointer\n",
    "\n",
    "### Copy IOP 'DataSet' ##\n",
    "iop_out = iop_in\n",
    "\n",
    "## Clean out existing variables and obsolete attributes ##\n",
    "iop_out = iop_in.drop(iop_in.data_vars)\n",
    "del(iop_out.attrs['history'])\n",
    "del(iop_out.attrs['nco_openmp_thread_number']) \n",
    "del(iop_out.attrs['NCO'])\n",
    "\n",
    "## Fill out known info. now ##\n",
    "iop_out['lon'] = [np.float32(iop_lon)] # need [] here so it gets treated as a 0d array coordinate\n",
    "iop_out['lat'] = [np.float32(iop_lat)]\n",
    "iop_out.lat.attrs = iop_in.lat.attrs\n",
    "iop_out.lon.attrs = iop_in.lon.attrs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Add Time (tsec) Array Based on time information ##\n",
    "ntsteps = int(tperiod/dtime)\n",
    "time = iop_zstart+dtime*np.arange(ntsteps)\n",
    "\n",
    "## Copy attributes of tsec from iop_in ##\n",
    "iop_out.coords['tsec'] = ('time', time)\n",
    "iop_out.tsec.attrs['long_name'] = iop_in.tsec.attrs['long_name'] \n",
    "iop_out.tsec.attrs['units'] = iop_in.tsec.attrs['units'] \n",
    "iop_out['bdate'] = bdate\n",
    "\n",
    "## Open New IOP/netcdf/DataSet and add attributes ##\n",
    "iop_out.attrs['title'] = 'Southeast Atmosphere Study (SAS) campaign: Ideal day for the Mixed Layer Model (MXLCH, it can be accessed athttps://github.com/classmodel/mxlch)'\n",
    "iop_out.attrs['iop_file'] = iop_file_out\n",
    "iop_out.attrs['publication'] = 'https://doi.org/10.5194/acp-16-7725-2016'\n",
    "iop_out.attrs['creation_date'] = str(dt.datetime.today())\n",
    "iop_out.attrs['creation_date'] = 'Rich Neale, NCAR'\n",
    "\n",
    "## Set up a basoiope 3D/4D DataArray that will be written into the new DataSet\n",
    "var_4d = np.zeros((ntsteps,nplevs,1,1),dtype=np.float32) # Set-up\n",
    "var_3d = np.zeros((ntsteps,1,1),  dtype=np.float32) # Set-up\n",
    "\n",
    "iop_out_c4 = ('time','lev','lat','lon')   # Coordinates for iop_out\n",
    "iop_out_c3 = ('time','lat','lon')\n",
    "\n",
    "\n",
    "\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Need constants ###\n",
    "\n",
    "r_gas = 287.   # Specific gas constant for dry air\n",
    "cp_air = 1004.6 # Specific heat for dry air\n",
    "Lv = 2.501e6      # Latent heat of vaporization\n",
    "\n",
    "r_cp = r_gas/cp_air    # r/cp\n",
    "grav = 9.81     # Gravity ave.\n",
    "\n",
    "plevs = 100.*np.arange(10,1000,10)\n",
    "nplevs = plevs.size\n",
    "\n",
    "    \n",
    "###### Construct time varying data for 3d arrays (time,lat,lon) ######\n",
    "\n",
    "## Generate boundary forced variables ##\n",
    "shflx0 = vval[vname.index('shflx')]\n",
    "vdesc_i = vdesc[vname.index('shflx')]\n",
    "\n",
    "lhflx0 = vval[vname.index('lhflx')]\n",
    "vdesc_i = vdesc[vname.index('lhflx')]\n",
    "\n",
    "## SAS case study: Daylight variation of sfce fluxes (sfc fluxes to be converted to energy flux) ##\n",
    "shflx = np.copy(var_3d)  \n",
    "shflx[:,0,0] = shflx0*cp_air*np.sin(np.pi*(time-iop_zstart)/tperiod)\n",
    "iop_out['shflx'] = (iop_out_c3, shflx)\n",
    "#plevs = iop_in['lev']\n",
    "iop1_out = xr.Dataset({'shflx': (['tsec','lon','lat'],  shflx)},\n",
    "                     coords={'tsec': ('tsec',time),  \n",
    "                             'lev': ('lev',plevs), \n",
    "                             'lon': ('lon',[iop_lon]), \n",
    "                             'lat': ('lat', [iop_lat]) })\n",
    "#iop_out1 = xr.Dataset(data_vars={\"temperature: da_temperature, \"pressure\": da_pressure})\n",
    "print(iop1_out)\n",
    "lhflx = np.copy(var_3d)  \n",
    "lhflx[:,0,0] = 0.001*lhflx0*Lv*np.sin(np.pi*(time-iop_zstart)/tperiod) # Convert g/kg -> kg/kg\n",
    "iop_out['lhflx'] = (iop_out_c3, lhflx)\n",
    "\n",
    "\n",
    "## Quick plots ##\n",
    "\n",
    "fig,ax = mp.subplots(nrows=1, ncols=2,figsize=(12, 5))\n",
    "fig.suptitle('lhflx/shflx')\n",
    "ax[0].plot((time/sph)-6,lhflx[:,0,0])\n",
    "ax[1].plot((time/sph)-6,shflx[:,0,0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e48333c8478f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m## Z of plevels, tricky don't have T yet ##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdp_levs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplevs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "### Constructing vertical profiles ###\n",
    "## Read in SCAM IOP template here (split into a function at some point)\n",
    "#plevs = np.array([10, 20, 100, 150, 200, 300, 400, 500, 550, 600, 650, 700, 750, 800, 850, 900, 950, 975, 1000])\n",
    "#plevs = np.arange(10,1000,10)\n",
    "\n",
    "\n",
    "## Convert trop theta values into temperature given plevs ##\n",
    "#plevs = iop_in['lev']\n",
    "\n",
    "\n",
    "ps = 101500. # psurf [pa]\n",
    "p0 = 100000. # pref [pa]\n",
    "\n",
    "## Z of plevels, tricky don't have T yet ##\n",
    "dp_levs = np.diff(plevs)\n",
    "\n",
    "\n",
    "##### Construct profile ICs #######\n",
    "\n",
    "## 1. Grab CASE values ##\n",
    "pblh =  vval[vname.index('pblh')]\n",
    "\n",
    "the_ft = vval[vname.index('the_trop')]\n",
    "the_bl = vval[vname.index('the_bl')]\n",
    "dthedp_ft =  vval[vname.index('the_lr')]\n",
    "\n",
    "q_ft = vval[vname.index('q_trop')]\n",
    "q_bl = vval[vname.index('q_bl')]\n",
    "dqdp_ft = vval[vname.index('q_lr')]\n",
    "\n",
    "\n",
    "\n",
    "## 2. Find PBL top level ##\n",
    "\n",
    "# Temperature profile based just on the_bl\n",
    "t_bl = the_bl*(plevs/p0)**r_cp  \n",
    "\n",
    "# Assumed t is just below 800mb\n",
    "p_bl_top = 80000. # hpa estimate pf PBL top.\n",
    "t_bl_ave = np.average(t_bl[np.where(plevs >= p_bl_top)])\n",
    "\n",
    "# Z levels based on t_bl\n",
    "z_plevs = (r_gas/grav)*t_bl*np.log(ps/plevs)\n",
    "print(z_plevs)\n",
    "# Where's the PBL?\n",
    "ipbl_levs = np.where(z_plevs <= pblh)\n",
    "npbl_levs = np.size(ipbl_levs)\n",
    "nft_levs = nplevs-npbl_levs\n",
    "\n",
    "ipbl_min = np.amin(ipbl_levs)\n",
    "\n",
    "\n",
    "## 3. Use Gradient+mean and specified theta, q for profiles ##\n",
    "\n",
    "q_plevs = np.full(nplevs, q_bl)\n",
    "the = np.full(nplevs, the_bl) # Initialize theta pbl as numpys\n",
    "\n",
    "# Construct profiles in the FT, starting at ipbl+ and working up\n",
    "\n",
    "for ip in range(ipbl_min-1,-1,-1):\n",
    "#    print(\"LEV --> \",ip,plevs[ip].data)\n",
    "    \n",
    "    # Temp profile\n",
    "    t_ip = the[ip-1]*(plevs[ip-1]/p0)**r_cp # Temp at the level below\n",
    " \n",
    "    rho = plevs[ip]/(r_gas*t_ip)  # Density at lev-=ip\n",
    "    dz = dp_levs[ip]/(rho*grav)\n",
    "    the[ip] = the[ip+1]+dthedp_ft*dz\n",
    "\n",
    "#    print(\"T ->\",t_ip.data,rho.data,dz.data,the[ip])\n",
    "    \n",
    "    # q profile \n",
    " \n",
    "    q_plevs[ip] = q_plevs[ip+1]+dqdp_ft*dz\n",
    "\n",
    "#    print(\"q ->\",q_plevs[ip],dz.data,dqdp_ft*dz.data)\n",
    "#    print(\"\")\n",
    "\n",
    "## Set temp\n",
    "temp_plevs = the*(plevs/p0)**r_cp\n",
    "\n",
    "## Don't let q go below a minimum (linear gradient will do that), or tail the value expoentially\n",
    "#q_plevs[np.where(q_plevs <= 0)] = 0.1\n",
    "\n",
    "## Exponential tailing \n",
    "\n",
    "ip0 = np.where(q_plevs <= 0)\n",
    "ip0m = np.max(ip0)+1\n",
    "ew = np.exp((plevs[ip0m]-plevs[ip0])/plevs[ip0m]) # Exponential weights \n",
    "ew = ew[::-1] # flip weights due to order of \n",
    "ew = (ew/np.exp([1]))**5 # Normaliz to 1 and **2 for stronger tailing at lower pressure \n",
    "q_plevs[ip0] = q_plevs[ip0m]*ew\n",
    "\n",
    "## Quick plots ##\n",
    "\n",
    "fig1,axs = mp.subplots(nrows=1, ncols=2,figsize=(12, 5))\n",
    "fig1.suptitle('T/q')\n",
    "axs[0].invert_yaxis()\n",
    "axs[1].invert_yaxis()\n",
    "axs[0].plot(temp_plevs.transpose(), plevs)\n",
    "axs[1].plot(q_plevs.transpose(), plevs)\n",
    "axs[1].axvline(0, color='black',linestyle=\"--\")\n",
    "\n",
    "\n",
    "\n",
    "#z_plevs = (r_gas/grav)*np.mean(temp_plevs)*np.log(ps/plevs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[110.69155046 124.6903458  137.73879563 147.72055968 155.90210259\n",
      " 162.88081583 168.99153768 174.44265334 179.37346679 183.88210352\n",
      " 188.04050787 191.9031279  195.51224524 198.90140208 202.09769045\n",
      " 205.12333155 207.99679526 210.73361263 213.34697766 215.84820123\n",
      " 218.24705876 220.5520606  222.77066473 224.90944615 226.97423329\n",
      " 228.97021864 230.90204958 232.7739033  234.58954918 236.35240107\n",
      " 238.06556134 239.73185831 241.35387808 242.93399188 244.47437963\n",
      " 245.9770503  247.44385963 248.87652555 250.27664174 251.64568952\n",
      " 252.98504834 254.29600504 255.57976211 256.83744503 258.07010878\n",
      " 259.27874374 260.46428091 261.62759668 262.76951703 263.89082143\n",
      " 264.99224632 266.07448822 267.13820668 268.18402685 269.21254188\n",
      " 270.22431508 271.21988197 272.19975204 273.16441049 274.11431976\n",
      " 275.04992095 275.9716351  276.87986447 277.77499363 278.65739046\n",
      " 279.52740719 280.38538123 281.23163601 282.06648179 282.89021634\n",
      " 283.70312562 284.50548442 285.29755693 286.07959727 286.85185004\n",
      " 287.61455078 288.3679264  289.11219564 289.84756943 290.57425128\n",
      " 291.29243762 292.00231813 292.70407608 293.39788856 294.08392682\n",
      " 294.76235648 295.43333781 296.09702596 296.75357115 297.4031189\n",
      " 298.04581024 298.68178186 299.31116633 299.93409224 300.55068435\n",
      " 301.16106377 302.03025355 302.89306591 303.74961202]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "conflicting sizes for dimension 'lev': length 99 on 'T' and length 18 on 'lev'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-238cac19e6e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# 4D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0miop_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'T'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0miop_out_c4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0miop_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'q'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0miop_out_c4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1000.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Funny SCAM requirments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/analysis/lib/python3.7/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1075\u001b[0m                                       'to set Dataset values')\n\u001b[1;32m   1076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1077\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__delitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/analysis/lib/python3.7/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, other, inplace)\u001b[0m\n\u001b[1;32m   2745\u001b[0m         \"\"\"\n\u001b[1;32m   2746\u001b[0m         \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2747\u001b[0;31m         \u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoord_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_update_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2749\u001b[0m         return self._replace_vars_and_dims(variables, coord_names, dims,\n",
      "\u001b[0;32m~/miniconda3/envs/analysis/lib/python3.7/site-packages/xarray/core/merge.py\u001b[0m in \u001b[0;36mdataset_update_method\u001b[0;34m(dataset, other)\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m     return merge_core([dataset, other], priority_arg=1,\n\u001b[0;32m--> 592\u001b[0;31m                       indexes=dataset.indexes)\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/analysis/lib/python3.7/site-packages/xarray/core/merge.py\u001b[0m in \u001b[0;36mmerge_core\u001b[0;34m(objs, compat, join, priority_arg, explicit_coords, indexes)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[0massert_unique_multiindex_level_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mdims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexplicit_coords\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/analysis/lib/python3.7/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36mcalculate_dimensions\u001b[0;34m(variables)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 raise ValueError('conflicting sizes for dimension %r: '\n\u001b[1;32m    117\u001b[0m                                  \u001b[0;34m'length %s on %r and length %s on %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                                  (dim, size, k, dims[dim], last_used[dim]))\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: conflicting sizes for dimension 'lev': length 99 on 'T' and length 18 on 'lev'"
     ]
    }
   ],
   "source": [
    "## Other profile arrays which are easy array copies ##\n",
    "\n",
    "\n",
    "\n",
    "## Write out data to iop fiel 4d array structure, just copying initial temp to all times ##\n",
    "\n",
    "# Constant value copying\n",
    "\n",
    "# Omega (units are /s which don't make sense, maybe m/s)\n",
    "w_sub = vval[vname.index('w_sub')]\n",
    "omega = np.copy(var_4d) # Copy 4D array\n",
    "\n",
    "# divt and divq (horizontal advection)\n",
    "q_adv = vval[vname.index('q_adv')]\n",
    "the_adv = vval[vname.index('the_adv')]\n",
    "\n",
    "divT = np.copy(var_4d) # Copy 4D array, need to convert to Temp in the array u.del(the)->u.del(T)\n",
    "divq = np.full_like(var_4d,0.001*q_adv) # Single value overwrite everywhere, convert g/kg/s->kg/kg/s\n",
    "\n",
    "# Calculated above\n",
    "T = np.copy(var_4d)  \n",
    "q = np.copy(var_4d) \n",
    "\n",
    "print(temp_plevs)\n",
    "for it in range(0, ntsteps):\n",
    "   T[it,:,0,0] = temp_plevs.data[:]\n",
    "   q[it,:,0,0] = q_plevs.data[:]\n",
    "   divT[it,:,0,0] = the_adv*(plevs/p0)**r_cp # Constant in theta bbut not in T.\n",
    "\n",
    "   rho = plevs/(r_gas*t_ip)  # Convert dw/dz -> dw/dp\n",
    "   omega[it,:,0,0] = w_sub/(rho*grav)\n",
    "\n",
    "## Write to IOP file ##\n",
    "\n",
    "# 3D\n",
    "iop_out['lhflx'] = (iop_out_c3, lhflx)\n",
    "iop_out.lhflx.attrs = iop_in.lhflx.attrs \n",
    "\n",
    "iop_out['shflx'] = (iop_out_c3, shflx)\n",
    "iop_out.shflx.attrs = iop_in.shflx.attrs \n",
    "\n",
    "# 4D\n",
    "iop_out['T'] = (iop_out_c4, T)\n",
    "iop_out['q'] = (iop_out_c4, np.float_(q/1000.)) # Funny SCAM requirments\n",
    "\n",
    "if lno_lsf: # Set ls forcings to zero\n",
    "    divq.fill(0.) ; divT.fill(0.) ; omega.fill(0.)\n",
    "    \n",
    "iop_out['divq'] = (iop_out_c4, divq)\n",
    "iop_out['divT'] = (iop_out_c4, divT)\n",
    "iop_out['omega'] = (iop_out_c4, omega)\n",
    "\n",
    "for iv in iop_out.data_vars:\n",
    "    iop_out[iv].attrs = iop_in[iv].attrs \n",
    "    print(iop_in[iv].attrs)\n",
    "    iop_out[iv].attrs['_FillValue'] = -9999.\n",
    "    iop_out[iv].attrs['missing_value'] = -9999. \n",
    "\n",
    "\n",
    "\n",
    "# Send everything to output IOP file\n",
    "iop_out.to_netcdf(iop_file_out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
