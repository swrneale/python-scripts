{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr>\n",
    "\n",
    "# Program plots profiles of state variables and process tendencies at various locations and times of ENSO phase\n",
    "\n",
    "<ul>\n",
    "<li> Level 1: Mean profiles of states and tendencies during ENSO phase (seasons: monthly means) </li>\n",
    "<li> Level 2: Time varying profiles during a season or seasonal transtion </li>\n",
    "<li> Level 3: Statistical reltiosnhips between vertical processes and ENSO/forcing/dynamical strength </li>\n",
    "</ul>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as mp\n",
    "import xarray as xr\n",
    "import datetime as dt\n",
    "#from dateutil.relativedelta import relativedelta\n",
    "\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import pandas as pd\n",
    "import metpy as mpy\n",
    "import dask as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### To Import My Functions ###\n",
    "import vert_prof_func as mypy\n",
    "import vert_prof_case_desc as mycase\n",
    "import importlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Initial Simulation Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "importlib.reload(mypy) # Required because I am constantly editing scam_func.py\n",
    "importlib.reload(mycase) # Required because I am constantly editing scam_func.py\n",
    "\n",
    "\n",
    "''''' Which case to use '''''\n",
    "\n",
    "case_desc = []\n",
    "\n",
    "''' ##### REVERT EXPERIMENTS ##### '''\n",
    "\n",
    "#case_desc = np.array(['C6','C5','rC5now','rUW','rUWp','rMG1','rC5p','rC5pm','rZMc','rZMp','rpfrac','rCE2i']) ; pref_out = 'revert'\n",
    "#case_desc = np.array(['C6','rC5','rCE2i','rUW','rMG1','rC5p','rZMc','rZMp','rpfrac','rTMS','rGW']) ; pref_out = 'revert'                      \n",
    "\n",
    "#case_desc = ['C6','rC5','rCE2i','rC5p','rUW','rUWp','rZMp'] ; pref_out = 'revert_test'   \n",
    "\n",
    "case_desc = ['C6','rC5'] \n",
    "nrevert = len(case_desc)\n",
    "case_type = ['cam6_revert']*nrevert\n",
    "\n",
    "\n",
    "\n",
    "''' ##### SETTINGS INCLUDING ENSEMBLES ###### '''\n",
    "\n",
    "#pref_out = 'lens2'    \n",
    "nens = 2\n",
    "\n",
    "#case_desc = ['CE2.E%01d'%(itt) for itt in range(8,nens+8)]\n",
    "#case_type  = ['lens2']*nens\n",
    "\n",
    "#case_desc = ['C6.E%01d'%(itt) for itt in range(1,nens+1)]\n",
    "#case_type  = ['c6_amip']*nens\n",
    "\n",
    "\n",
    "\n",
    "''' ###### REANAL+ABOVE MODEL SIMS ######## '''\n",
    "\n",
    "#pref_out = 'c5_amip_reanal_era5'\n",
    "pref_out = 'cam56_ERA5_MERRA2'\n",
    "\n",
    "#case_reanal = ['ERA5','ERAI','CFSR','MERRA2','JRA25'] \n",
    "#type_reanal = ['reanal','reanal','reanal','reanal','reanal']\n",
    "\n",
    "case_reanal = ['ERA5','MERRA2'] \n",
    "type_reanal = ['reanal','reanal']\n",
    "\n",
    "\n",
    "reanal_climo = True # Grab climo. values for mean, Nino and nina events for reanalysis only\n",
    "\n",
    "#case_desc = np.array(case_reanal)\n",
    "#case_type = np.array(type_reanal)\n",
    "\n",
    "\n",
    "case_desc = np.array(case_reanal+case_desc)\n",
    "case_type = np.array(type_reanal+case_type)\n",
    "\n",
    "\n",
    "#case_desc = np.array(case_desc)\n",
    "#case_type = np.array(case_type)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## INDIVIDUAL CASE SETTINGS/ADDITIONS ##\n",
    "\n",
    "''''' Which nino SST region '''''\n",
    "nino_region = 'nino34'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "''' SEASON '''\n",
    "\n",
    "seas_mons = np.array([\"Jan\",\"Feb\",\"Dec\"])\n",
    "\n",
    "clim_anal = False\n",
    "\n",
    "''''' Years for the analysis '''''\n",
    "\n",
    "years_data = (1979,2005) # Year range of history files to read AND either 'climo' one file or 'tseries' many files\n",
    "\n",
    "\n",
    "''' REGIONAL SPECS (LAT/LON/LEV) '''\n",
    "\n",
    "#lats_in = -10. ; latn_in = 5.\n",
    "#lonw_in = 150. ; lone_in = 220.\n",
    "ppmin = 50. ; ppmax = 1000.\n",
    "\n",
    "\n",
    "\n",
    "''''' Variable description '''''\n",
    "\n",
    "var_cam = 'U'\n",
    "ldiv = False # Calculate divergence from OMEGA if var_Cam = OMEGA\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "''''' Directory Information '''''\n",
    "\n",
    "dir_croot = '/glade/p/cgd/amp/people/hannay/amwg/climo/' # Directories with climo files\n",
    "dir_hroot = '/glade/p/cgd/amp/amwg/runs/' # Run firectories with history files\n",
    "\n",
    "dir_proot = '/glade/u/home/rneale/python/python-figs/vert_proc/'\n",
    "dir_obs = '/glade/p/cesm/amwg/amwg_data/obs_data/'\n",
    "\n",
    "\n",
    "\n",
    "## Variables ##\n",
    "\n",
    "var_desc = {}\n",
    "\n",
    "var_desc['DTCOND'] = ['dT/dt Total',86400.,1., -5.,5.,-2.,2.,'K/day']\n",
    "var_desc['DCQ']    = ['dq/dt Total',86400*1000.,1., -4.,4.,-4.,4.,'g/kg/day']\n",
    "var_desc['ZMDT']   = ['dT/dt Convection',86400., 1.,-5.,5.,-2.,2.,'K/day']\n",
    "var_desc['ZMDQ']   = ['dq/dt Convection',86400.*1000., 1.,-4.,4.,-4.,4.,'g/kg/day']\n",
    "var_desc['STEND_CLUBB'] = ['dT/dt turbulence',86400./1004., 1. ,-2.,8.,-2.,8.,'K/day']\n",
    "var_desc['OMEGA'] = ['OMEGA',-1., -1., -0.06,0.06,-0.06,0.06,'pa/s']\n",
    "var_desc['DIV'] = ['Divergence',1., 100./86400., -0.0004,0.0004,-0.0004,0.0004,'s^-1']\n",
    "var_desc['T'] = ['Temperature',1., 1., 180.,300.,-2.,2.,'K']\n",
    "var_desc['Q'] = ['Specific Humidity',1000., 1000., 0.,20.,-0.5,0.5,'g/kg']\n",
    "var_desc['U'] = ['Zonal Wind',1., 1., -60.,60.,-10.,10.,'m/s']\n",
    "\n",
    "\n",
    "\n",
    "''''' Named Regions '''''\n",
    "\n",
    "reg_names = {}\n",
    "\n",
    "#### RBN Original Locations ####\n",
    "\n",
    "#reg_names['Nino Wet'] = ['C. Pacific Nino Wet',-10,0.,160.,210]  # Core of nino precip signal\n",
    "#reg_names['WP Dry']   = ['West Pac. Nino Dry.',-5.,10.,120.,150]  # Core of W. Pacific signal\n",
    "#reg_names['Conv U']   = ['Convergence Min',25,50.,160,190]       # Core of RWS convergence min.\n",
    "#reg_names['CE Pac']   = ['East Pacific ITCZ',5,10.,220,270]       # Core of RWS convergence min.\n",
    "\n",
    "#### Anna Locations ####\n",
    "#reg_names['Nino Wet'] = ['C. Pacific Nino Wet',-10,0.,160.,220]  # Core of nino precip signal#\n",
    "#reg_names['WP Dry']   = ['West Pac. Nino Dry.',0.,15.,110.,150]  # Core of W. Pacific signal\n",
    "reg_names['Conv U']   = ['Convergence Min',25,40.,150,200]       # Core of RWS convergence min.\n",
    "\n",
    "\n",
    "#1. positive precipitation anomalies -equatorial central Pacific : 160E-140W; 10S-EQ (Main tropical forcing)\n",
    "#2. Divergence anomalies subtropical North Pacific: 150E-160W; 25-40N (RWS generation region)\n",
    "#3. Negative precipitation anomalies western Pacific: 110E-150E; EQ-15N (Additional contribution to RWS) \n",
    "\n",
    "# Include observations? #\n",
    "lobs = False\n",
    "\n",
    "# Pressure info.\n",
    "\n",
    "p_levs = np.arange(ppmin,ppmax,50.)\n",
    "\n",
    "\n",
    "\n",
    "###### NAMES CATALOGUE ######\n",
    "#sim_names = cam_revert_list()\n",
    "#sim_names = cam_vres_list()\n",
    "#sim_names = mycase.cam_reanal_list()\n",
    "sim_names = mycase.mdtf_case_list()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Specify data frames ##\n",
    "print(reg_names)\n",
    "reg_df = pd.DataFrame.from_dict(reg_names, orient='index',columns=['long_name','lat_s','lat_n','lon_w','lon_e'])\n",
    "var_df = pd.DataFrame.from_dict(var_desc, orient='index',columns=['long_name','vscale','ovscale','xmin','xmax','axmin','axmax','vunits'])\n",
    "\n",
    "display(reg_df)\n",
    "print()\n",
    "display(var_df)\n",
    "\n",
    "reg = list(reg_names.keys())[0]\n",
    "\n",
    "reg_s = reg_df.loc[reg]['lat_s'] ; reg_n = reg_df.loc[reg]['lat_n']\n",
    "reg_w = reg_df.loc[reg]['lon_w'] ; reg_e = reg_df.loc[reg]['lon_e']\n",
    " \n",
    "\n",
    "nmnths = seas_mons.size\n",
    "ncases = case_desc.size\n",
    "nregions = reg_df.index.size\n",
    "\n",
    "xmin = var_df.loc[var_cam]['xmin'] ; xmax=var_df.loc[var_cam]['xmax']\n",
    "axmin = var_df.loc[var_cam]['axmin'] ; axmax=var_df.loc[var_cam]['axmax']                     \n",
    "vunits = var_df.loc[var_cam]['vunits'] \n",
    "var_text = var_df.loc[var_cam]['long_name']   \n",
    "var_pname = var_cam\n",
    "\n",
    "if ldiv and var_cam == 'OMEGA':\n",
    "    var_pname = 'DIV'\n",
    "    var_text = var_df.loc[var_pname]['long_name']     \n",
    "    vunits = var_df.loc[var_pname]['vunits'] \n",
    "    xmin = var_df.loc[var_pname]['xmin'] ; xmax=var_df.loc[var_pname]['xmax']\n",
    "    axmin = var_df.loc[var_pname]['axmin'] ; axmax=var_df.loc[var_pname]['axmax']                \n",
    "    \n",
    "\n",
    "#%matplotlib inline\n",
    "ds.config.set({\"array.slicing.split_large_chunks\": True})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENSO Phase Compositing of Tendencies \n",
    "- Read in hist timeseries\n",
    "- Calculate SST nino timeseries\n",
    "- Composites based on season for vertical profiles\n",
    "- Composites vertical profiles minus climo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "importlib.reload(mypy) # Required because I am constantly editing scam_func.py\n",
    "importlib.reload(mycase) # Required because I am constantly editing scam_func.py\n",
    "\n",
    "\n",
    "\n",
    "# importlib.reload(mypy) # Required because I am constantly editing scam_func.py\n",
    "\n",
    "### Read in history monthly mean files and composite profiles for tendencies###\n",
    "dir_hroot = '/glade/p/cgd/amp/amwg/runs/'\n",
    "\n",
    "#### Read in Data ####\n",
    "\n",
    "yr0 = years_data[0]\n",
    "yr1 = years_data[1]\n",
    "\n",
    "\n",
    "nino_names = ['Climatology ('+str(yr0)+'-'+str(yr1)+')','El Nino','La Nina']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  ## PLOTTING RESOURCES\n",
    "\n",
    "fign, axn = mp.subplots(1,3,figsize=(26, 11))  \n",
    "fign.patch.set_facecolor('white') # Sets the plot background outside the data area to be white. Remove to make it transparent.\n",
    "\n",
    "nino_colors = ['black','red','blue']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "########################\n",
    "##### LOOP CASES  ######\n",
    "########################\n",
    "'''\n",
    "\n",
    "\n",
    "for icase,case in enumerate(case_desc): # Do first so don't have to do a read mutliple times\n",
    "\n",
    "# Grab run name \n",
    "    \n",
    "    sim_name = sim_names.loc[case]['run name']\n",
    "    \n",
    "    lclimo = True if reanal_climo and case_type[icase] == 'reanal' else False\n",
    "   \n",
    "    \n",
    "    print('')\n",
    "    print('')\n",
    "    print('')\n",
    "    print('**** **** **** **** **** **** **** **** **** ')\n",
    "    print('**** CASE # ',[icase+1],' OF ',ncases,' ****')\n",
    "    print('**** **** **** **** **** **** **** **** **** ')\n",
    "    print('- Name = ',case,' ->',sim_name)\n",
    "    print('**** **** **** **** **** **** **** **** **** ')\n",
    "    print('')   \n",
    "        \n",
    "        \n",
    "## Read data in from files ##\n",
    "\n",
    "# Construct required history file month-year array\n",
    "\n",
    "#    hist_myr = np.array([\".cam.h0.%d-%02d.nc\"%(y, m) for y in range(yr0,yr1+1) for m in range(1,12+1)])\n",
    "#    num_h0 = hist_myr.size\n",
    "  \n",
    "\n",
    "#    hfile_var = get_files_tseries(run_type,case_type,True) # Grab SST files\n",
    "   \n",
    "    print('-- SET TIME RANGE OF TIMESERIES DATA -- ',yr0,' to ',yr1)\n",
    "    print('-- Grabbing variable files --')\n",
    "    \n",
    "    if lclimo:  # Read in tseries based files here for the analysis variable\n",
    "        files_ptr,var_name   = mypy.get_files_climo(sim_name,case_type[icase],var_cam,years_data) # Grab variable\n",
    "    else :\n",
    "        files_ptr,var_name   = mypy.get_files_tseries(sim_name,case_type[icase],var_cam,years_data) # Grab variable\n",
    "    \n",
    "    \n",
    "   \n",
    "## TS FROM HISTORY FILES (just copy for h0 files if they are already read in)\n",
    "## Can still do this for lclimo as it will take observed if reanal\n",
    "\n",
    "    print('-- Grabbing SST files --')\n",
    "    if case_type[icase] in ['cam6_revert']: # I think this effectively acts as a pointer, I hope!\n",
    "        tfiles_ptr = files_ptr \n",
    "        tvar_name = 'TS'\n",
    "    else :   \n",
    "        tfiles_ptr,tvar_name = mypy.get_files_tseries(sim_name,case_type[icase],'TS',years_data) # Grab TS for nino timeseries\n",
    "\n",
    "\n",
    "# Have to modify based on month 1 is jan and not feb\n",
    "#    hfiles_ptr.time.dt.month[0]=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#    hmonths = hfiles_ptr.time.dt.month    \n",
    "\n",
    "    ''' TRIM FOR SPECIFIED YEARS '''\n",
    "    \n",
    "   \n",
    "    print('-- Calculating and plotting nino SST anomalies')\n",
    "    \n",
    "    sst_data = tfiles_ptr[tvar_name].sel(time=slice(str(yr0), str(yr1)))\n",
    "   \n",
    "    \n",
    "    ''' SST ANOMALY ROUTINE ARRAY '''\n",
    "  \n",
    "    sst_months =  sst_data.time.dt.strftime(\"%b\")    \n",
    "    inino_mons,inina_mons = mypy.nino_sst_anom(sim_name,sst_data,nino_region)\n",
    "    \n",
    "    print('-- NINO grab:  Done --')\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    ''' SUBSET SEASON MONTHS '''\n",
    "    \n",
    "#    print(files_ptr[var_name].dt)     \n",
    "#    date_after_month = date.today()+ relativedelta(months=1)\n",
    "#    print ('Today: ',date.today().strftime('%d/%m/%Y'))\n",
    "#    print ('After Month:', dt.strftime('%d/%m/%Y'))\n",
    "\n",
    "#    dt_index = files_ptr.indexes['time'].to_datetimeindex()\n",
    "#    print(dt.date.today())\n",
    "#    print(dt_index.month)\n",
    "#    print(relativedelta(months=-1))\n",
    "#    print(dt.date.today()+relativedelta(months=-10))\n",
    "\n",
    "#    print(dt_index+relativedelta(months=+1))\n",
    "\n",
    "#    print(dt_index.month)\n",
    "    \n",
    "    \n",
    "#    time = files_ptr.time \n",
    "#    print(dt_index)\n",
    "#    files_ptr['time'] = dt_index \n",
    "    \n",
    "#    hmonths = files_ptr.time.dt.strftime(\"%b\")\n",
    " \n",
    "#    print(files_ptr.time.time)\n",
    "#    print(pd.to_datetime(files_ptr.time))\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    " \n",
    "   \n",
    "        \n",
    "# Just read in the season months and levs we need\n",
    "    \n",
    "   \n",
    "    if not lclimo:\n",
    "        \n",
    "        ## Need to split what is done fo climo versus tseries here.\n",
    "\n",
    "        \n",
    "        var_in = files_ptr[var_name].sel(time=slice(str(yr0),str(yr1)))\n",
    "        \n",
    "\n",
    "        if case_type[icase] in ['lens1','lens2','c6_amip']:\n",
    "            print('-- \"Compute\" the variable array now (bring it up from lazy array) if != ANALYSES')\n",
    "            %time var_in = var_in.compute()\n",
    "\n",
    "    # Grab time coord.\n",
    "        time_in = var_in.time\n",
    "\n",
    "\n",
    "        ''' Need to rename Vertical Pressure Coordinate '''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ''' Trim locations (lat/lev) for simplicity '''\n",
    "\n",
    "\n",
    "        lev_in = var_in.lev\n",
    "\n",
    "        ilevs = np.where(lev_in >= min(p_levs))\n",
    "\n",
    "        ilevs = ilevs[0]\n",
    "        lev = lev_in[ilevs]\n",
    "\n",
    "\n",
    "    # Check SST size with Variable size\n",
    "\n",
    "        if sst_data.time.size != time_in.size : print('SST and VARIABLE sizes DO NOT MATCH - ',sst_data.time.size,' and ',time_in.size) \n",
    "\n",
    "        month_nums = time_in.dt.month   \n",
    "        hmonths = time_in.dt.strftime(\"%b\")\n",
    "\n",
    "\n",
    "\n",
    "    # Poor man's modifcation for lens1 ts\n",
    "    #    if case_type[icase] == 'lens1' :\n",
    "    #            month_nums = month_nums-1 # Set back 1 month\n",
    "    #            month_nums[month_nums ==-1] = 12 # Set -1 months back to 12\n",
    "    #    mon_obj = dt.datetime.strptime(mon_nums, \"%m\")\n",
    "\n",
    "\n",
    "        lmon_seas = np.isin(hmonths,seas_mons) # Logical for seaon months in all months\n",
    "        imon_seas = np.argwhere(lmon_seas)[:,0] # Indices\n",
    "        hmon_seas = hmonths[imon_seas] # Subsetting full months.\n",
    "\n",
    "\n",
    "    # Seasonal selection for ninos \n",
    "\n",
    "    #    lnino_seas = np.isin(hmonths[inino_mons],seas_mons) # Logical for season months in all months\n",
    "    #    inino_seas= inino_mons[np.argwhere(lnino_seas)[:,0]] # Indices of origin nino_mons that match the season\n",
    "    #    inino_seas = np.argwhere(lnino_seas)[:,0] # Indices of origin nino_mons that match the season\n",
    "\n",
    "\n",
    "    #    lnina_seas = np.isin(hmonths[inina_mons],seas_mons) # Logical for season months in all months\n",
    "    #    inina_seas= inina_mons[np.argwhere(lnina_seas)[:,0]] # Indices of origin nino_mons that match the season\n",
    "    #    inina_seas= np.argwhere(lnina_seas)[:,0] # Indices of origin nino_mons that match the season   \n",
    "\n",
    "        var_in = var_in.loc[:,:,reg_s:reg_n,reg_w:reg_e] # Limit the levels\n",
    "\n",
    "    #  \n",
    "        var_in = var_in[:,ilevs,:,:]   \n",
    "        dp_lev = np.diff(lev)\n",
    "\n",
    "\n",
    "\n",
    "    ## Much easier than above but doing the intersections of months and nino months.\n",
    "        inino_seas,inino_ind,imon_nino_ind = np.intersect1d(inino_mons, imon_seas, return_indices=True)\n",
    "        inina_seas,inina_ind,imon_nina_ind = np.intersect1d(inina_mons, imon_seas, return_indices=True)\n",
    "\n",
    "\n",
    "    ## Could speed up below by reading in var_in for the season months then subsetting that for nino/nina    \n",
    "    ## Remember: It is reading in a subset of seaonal months and then nino/nina are a subset of those. \n",
    "\n",
    "        var_in_inseas = var_df.loc[var_cam]['vscale']*var_in[imon_seas,:,:,:] # Pull only the months we need\n",
    "      \n",
    "\n",
    "        if case_type[icase] in ['reanal','cam6_revert']:\n",
    "            print('-- \"Compute\" the variable array now (bring it up front lazy array) if == ANALYSES')\n",
    "            %time var_in_inseas = var_in_inseas.compute()\n",
    "\n",
    "        var_in_seas = var_in_inseas.mean(dim=['time'])  # Perform seasonal average\n",
    "\n",
    "        var_in_nino = var_in_inseas[imon_nino_ind,:,:,:].mean(dim=['time'])  # Take nino/nina months from the seasonal timeseries months\n",
    "        var_in_nina = var_in_inseas[imon_nina_ind,:,:,:].mean(dim=['time']) \n",
    "\n",
    "    \n",
    "    else :    ### Just grab separate data from climo, nino and nina files.\n",
    "        \n",
    "        var_in_seas =  files_ptr[var_name].isel(time=0)\n",
    "        var_in_nino =  files_ptr[var_name].isel(time=1)\n",
    "        var_in_nina =  files_ptr[var_name].isel(time=2)\n",
    "        \n",
    "        \n",
    "        lev_in = var_in_seas.lev\n",
    "        ilevs = np.where(lev_in >= min(p_levs))\n",
    "\n",
    "        lev = lev_in[ilevs]\n",
    "\n",
    "  \n",
    "        var_in_seas =  var_df.loc[var_cam]['ovscale']*var_in_seas.loc[lev[0]:lev[-1],reg_s:reg_n,reg_w:reg_e]\n",
    "        var_in_nino =  var_df.loc[var_cam]['ovscale']*var_in_nino.loc[lev[0]:lev[-1],reg_s:reg_n,reg_w:reg_e]\n",
    "        var_in_nina =  var_df.loc[var_cam]['ovscale']*var_in_nina.loc[lev[0]:lev[-1],reg_s:reg_n,reg_w:reg_e]\n",
    "\n",
    "    \n",
    "## USUAL WAY ##    \n",
    "    \n",
    "#    var_in_seas = var_df.loc[var_cam]['vscale']*var_in[imon_seas,:,:,:].mean(dim=['time']) \n",
    "#    var_in_nino = var_df.loc[var_cam]['vscale']*var_in[inino_seas,:,:,:].mean(dim=['time']) \n",
    "#    var_in_nina = var_df.loc[var_cam]['vscale']*var_in[inina_seas,:,:,:].mean(dim=['time']) \n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "    ########################    \n",
    "    ### Now Loop Regions ###\n",
    "    ########################\n",
    "    ''' \n",
    "    \n",
    "    for ireg,reg in enumerate(reg_df.index):  ## 4 regions let's assume ##\n",
    "\n",
    "### Assign lat/lon region domain ###\n",
    "        print(reg,ireg)\n",
    "        reg_name = reg_df.loc[reg]['long_name'] \n",
    "    \n",
    "#        reg_s = reg_df.loc[reg]['lat_s'] ; reg_n = reg_df.loc[reg]['lat_n']\n",
    "#        reg_w = reg_df.loc[reg]['lon_w'] ; reg_e = reg_df.loc[reg]['lon_e']\n",
    "        \n",
    "        print()\n",
    "        print('-- Region = ',reg_name,' - ',reg_s,reg_n,reg_w,reg_e)\n",
    "                   \n",
    "        reg_a_str = '%d-%d\\u00b0E %.1f-%d\\u00b0N' % (reg_w,reg_e,reg_s,reg_n)\n",
    "        reg_a_out = '%d-%dE_%.1f-%dN' % (reg_w,reg_e,reg_s,reg_n)  \n",
    "         \n",
    "        print('-- Averaging for region - ',reg_a_str)\n",
    "\n",
    "        \n",
    "        \n",
    "### Compute Seasonal/El Nino/La Nina profiles\n",
    "         \n",
    "\n",
    "    \n",
    "        varp_seas = var_in_seas.loc[:,reg_s:reg_n,reg_w:reg_e]\n",
    "        \n",
    "        if lclimo :\n",
    "            \n",
    "            varp_nino = var_in_nino.loc[:,reg_s:reg_n,reg_w:reg_e]\n",
    "            varp_nina = var_in_nina.loc[:,reg_s:reg_n,reg_w:reg_e]\n",
    "        \n",
    "        else :\n",
    "        \n",
    "            varp_nino = var_in_nino.loc[:,reg_s:reg_n,reg_w:reg_e]-varp_seas\n",
    "            varp_nina = var_in_nina.loc[:,reg_s:reg_n,reg_w:reg_e]-varp_seas\n",
    "        \n",
    "        varp_all = (varp_seas,varp_nino,varp_nina) # Put in tuple for looping.\n",
    "               \n",
    "        \n",
    "        \n",
    "        pmark,lcolor,lwidth  = ('x',None,3)   if case_type[icase] == 'reanal' else   (None,'red',1)  \n",
    "        if case_type[icase] == 'cam6_revert':\n",
    "            pmark,lcolor,lwidth = ('.',None,1)\n",
    "    \n",
    "              \n",
    "                           \n",
    "        '''\n",
    "        ####################################    \n",
    "        ### Loop climo/nino/nina periods ###\n",
    "        ####################################\n",
    "        '''     \n",
    "        \n",
    "## LOOP: Seasonal/El Nino/La Nina plots for this region.\n",
    " \n",
    "\n",
    "        for iplot,var_plot in enumerate(varp_all):\n",
    "            \n",
    "            print('    -- Period = '+nino_names[iplot])\n",
    "            pxmin = xmin if iplot == 0 else axmin\n",
    "            pxmax = xmax if iplot == 0 else axmax\n",
    "            \n",
    "# Regional average\n",
    "            var_fig = var_plot.mean(dim=['lat','lon'],skipna = True)   \n",
    "        \n",
    "        \n",
    "           \n",
    "            \n",
    "            if ldiv and var_cam == 'OMEGA':\n",
    "                var_fig = var_fig.differentiate(\"lev\")\n",
    "                \n",
    "           \n",
    "            axn[iplot].plot(var_fig,lev,lw=lwidth,markersize=9,marker=pmark,color=lcolor)  \n",
    " \n",
    "\n",
    "\n",
    "            if (icase==0) :\n",
    "                axn[iplot].set_title(nino_names[iplot],fontsize=20,color=nino_colors[iplot])\n",
    "                axn[iplot].set_xlim([pxmin,pxmax])\n",
    "                axn[iplot].set_ylim([ppmax,ppmin])\n",
    "                axn[iplot].set_ylabel('mb',fontsize=16) \n",
    "                axn[iplot].set_xlabel(vunits,fontsize=16)      \n",
    "                axn[iplot].set_yticks(p_levs)\n",
    "                axn[iplot].set_yticklabels(p_levs,fontsize=14)\n",
    "###                axn[iplot].set_xticklabels(np.arange(xmin,xmax,0.1*(xmax-xmin)),fontsize=12)\n",
    "                axn[iplot].tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "                axn[iplot].grid(linestyle='--')  \n",
    "                \n",
    "    \n",
    "            if ((pxmin < 0) and (pxmax > 0)) :\n",
    "                axn[iplot].vlines(0., ppmax, ppmin, linestyle=\"--\",lw=3, color='black')\n",
    "\n",
    "             \n",
    "    \n",
    "# Legend ### Perform a bit of logic for the  \n",
    "#rtypes, counts = np.unique(case_type, return_counts=True)\n",
    "#if counts.min == 1:\n",
    "leg_cases = case_desc\n",
    "\n",
    "# Don't repeat lens in legend if there are many cases.\n",
    "\n",
    "\n",
    "if 'lens1' in case_type : \n",
    "    leg_cases = [case_desc[0],'lens1']\n",
    "    if 'reanal' not in case_type :\n",
    "        leg_cases = ['lens1']\n",
    "        \n",
    "if 'lens2' in case_type : \n",
    "    leg_cases = [case_type[0],'lens2']\n",
    "    if 'reanal' not in case_type :\n",
    "        leg_cases = ['lens2']\n",
    "        \n",
    "if 'c6_amip' in case_type : \n",
    "    leg_cases = [case_type[0],'c6_amip']\n",
    "    if 'reanal' not in case_type :\n",
    "        leg_cases = ['c6_amip']\n",
    "    \n",
    "\n",
    "lloc = 'lower right' if var_name in ['ZMDQ','STEND_CLUBB'] else 'lower left' \n",
    "axn[0].legend(leg_cases,fontsize=15,loc = lloc)\n",
    "\n",
    "\n",
    "    # Main title\n",
    "fign.suptitle('ENSO Anomalies - '+reg_name+' -- '+reg_a_str+' - '+var_text,fontsize=20)\n",
    "\n",
    "mp.rcParams['xtick.labelsize'] = 15 # Global set of xtick label size    \n",
    "\n",
    "    \n",
    "#    mp.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Hard copy  \n",
    "fign.savefig(dir_proot+pref_out+'_nino_vprof_'+var_pname+'_'+reg_a_out+'_'+str(yr0)+'_to_'+str(yr1)+'.png', dpi=80)\n",
    "\n",
    "#mp.show()   |\n",
    "\n",
    "print()\n",
    "print()\n",
    "print('-- End Timing --')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-neale_myenv]",
   "language": "python",
   "name": "conda-env-miniconda3-neale_myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
