{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr>\n",
    "\n",
    "# Program plots profiles of state variables and process tendencies at various locations and times of ENSO phase\n",
    "\n",
    "<ul>\n",
    "<li> Level 1: Mean profiles of states and tendencies during ENSO phase (seasons: monthly means) </li>\n",
    "<li> Level 2: Time varying profiles during a season or seasonal transtion </li>\n",
    "<li> Level 3: Statistical reltiosnhips between vertical processes and ENSO/forcing/dynamical strength </li>\n",
    "</ul>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as mp\n",
    "import xarray as xr\n",
    "import datetime as dt\n",
    "#from dateutil.relativedelta import relativedelta\n",
    "\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import pandas as pd\n",
    "import metpy as mpy\n",
    "import dask as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### To Import My Functions ###\n",
    "import vert_prof_func as mypy\n",
    "import vert_prof_case_desc as mycase\n",
    "import importlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Initial Simulation Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ERA5</th>\n",
       "      <td>ERA5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERAI</th>\n",
       "      <td>ERAI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JRA25</th>\n",
       "      <td>JRA25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C4</th>\n",
       "      <td>f40.1979_amip.track1.1deg.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C5</th>\n",
       "      <td>30L_cam5301_FAMIP.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CE2.E36</th>\n",
       "      <td>b.e21.BHISTcmip6.f09_g17.LE2-1301.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CE2.E37</th>\n",
       "      <td>b.e21.BHISTcmip6.f09_g17.LE2-1301.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CE2.E38</th>\n",
       "      <td>b.e21.BHISTcmip6.f09_g17.LE2-1301.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CE2.E39</th>\n",
       "      <td>b.e21.BHISTcmip6.f09_g17.LE2-1301.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CE2.E40</th>\n",
       "      <td>b.e21.BHISTcmip6.f09_g17.LE2-1301.010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      run name\n",
       "ERA5                                      ERA5\n",
       "ERAI                                      ERAI\n",
       "JRA25                                    JRA25\n",
       "C4               f40.1979_amip.track1.1deg.001\n",
       "C5                       30L_cam5301_FAMIP.001\n",
       "...                                        ...\n",
       "CE2.E36  b.e21.BHISTcmip6.f09_g17.LE2-1301.006\n",
       "CE2.E37  b.e21.BHISTcmip6.f09_g17.LE2-1301.007\n",
       "CE2.E38  b.e21.BHISTcmip6.f09_g17.LE2-1301.008\n",
       "CE2.E39  b.e21.BHISTcmip6.f09_g17.LE2-1301.009\n",
       "CE2.E40  b.e21.BHISTcmip6.f09_g17.LE2-1301.010\n",
       "\n",
       "[107 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long_name</th>\n",
       "      <th>lat_s</th>\n",
       "      <th>lat_n</th>\n",
       "      <th>lon_w</th>\n",
       "      <th>lon_e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nino Wet</th>\n",
       "      <td>C. Pacific Nino Wet</td>\n",
       "      <td>-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    long_name  lat_s  lat_n  lon_w  lon_e\n",
       "Nino Wet  C. Pacific Nino Wet    -10    0.0  160.0    210"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long_name</th>\n",
       "      <th>vscale</th>\n",
       "      <th>ovscale</th>\n",
       "      <th>xmin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>vunits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DTCOND</th>\n",
       "      <td>dT/dt Total</td>\n",
       "      <td>8.640000e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-5.0000</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>K/day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DCQ</th>\n",
       "      <td>dq/dt Total</td>\n",
       "      <td>8.640000e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.0000</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>g/kg/day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZMDT</th>\n",
       "      <td>dT/dt Convection</td>\n",
       "      <td>8.640000e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-5.0000</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>K/day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZMDQ</th>\n",
       "      <td>dq/dt Convection</td>\n",
       "      <td>8.640000e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.0000</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>g/kg/day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STEND_CLUBB</th>\n",
       "      <td>dT/dt turbulence</td>\n",
       "      <td>8.605578e+01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.0000</td>\n",
       "      <td>8.0000</td>\n",
       "      <td>K/day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OMEGA</th>\n",
       "      <td>OMEGA</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-0.001157</td>\n",
       "      <td>-0.0040</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>pa/s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIV</th>\n",
       "      <td>Divergence</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>s^-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>Temperature</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U</th>\n",
       "      <td>Zonal Wind</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-5.0000</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>m/s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    long_name        vscale   ovscale     xmin     xmax  \\\n",
       "DTCOND            dT/dt Total  8.640000e+04  1.000000  -5.0000   5.0000   \n",
       "DCQ               dq/dt Total  8.640000e+07  1.000000  -4.0000   4.0000   \n",
       "ZMDT         dT/dt Convection  8.640000e+04  1.000000  -5.0000   5.0000   \n",
       "ZMDQ         dq/dt Convection  8.640000e+07  1.000000  -4.0000   4.0000   \n",
       "STEND_CLUBB  dT/dt turbulence  8.605578e+01  1.000000  -2.0000   8.0000   \n",
       "OMEGA                   OMEGA -1.000000e+00 -0.001157  -0.0040   0.0040   \n",
       "DIV                Divergence  1.000000e+00  0.001157  -0.0004   0.0004   \n",
       "T                 Temperature  1.000000e+00  1.000000 -10.0000  10.0000   \n",
       "U                  Zonal Wind  1.000000e+00  1.000000  -5.0000   5.0000   \n",
       "\n",
       "               vunits  \n",
       "DTCOND          K/day  \n",
       "DCQ          g/kg/day  \n",
       "ZMDT            K/day  \n",
       "ZMDQ         g/kg/day  \n",
       "STEND_CLUBB     K/day  \n",
       "OMEGA            pa/s  \n",
       "DIV              s^-1  \n",
       "T                   K  \n",
       "U                 m/s  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<dask.config.set at 0x7efd608a7df0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "importlib.reload(mypy) # Required because I am constantly editing scam_func.py\n",
    "importlib.reload(mycase) # Required because I am constantly editing scam_func.py\n",
    "\n",
    "\n",
    "''''' Which case to use '''''\n",
    "\n",
    "#case_desc = np.array(['C6','C5','rC5now','rUW','rUWp','rMG1','rC5p','rC5pm','rZMc','rZMp','rpfrac','rCE2i']) ; pref_out = 'revert'\n",
    "#case_desc = np.array(['C6','rC5','rCE2i','rUW','rMG1','rC5p','rZMc','rZMp','rpfrac','rTMS','rGW']) ; pref_out = 'revert'                      \n",
    "\n",
    "case_desc = ['C6','rC5','rCE2i','rC5p','rUW','rUWp','rZMp'] ; pref_out = 'revert_test'   \n",
    "\n",
    "#case_desc = ['C6','rC5'] ; pref_out = 'test'   \n",
    "nrevert = len(case_desc)\n",
    "case_type = ['cam6_revert']*nrevert\n",
    "\n",
    "\n",
    "\n",
    "## SETTINGS INCLUDING ENSEMBLES ##\n",
    "\n",
    "#pref_out = 'lens1_test1'    \n",
    "nens = 5\n",
    "\n",
    "#case_desc = ['CE1.E%01d'%(itt) for itt in range(1,nens+1)]\n",
    "#case_type  = ['lens1']*nens\n",
    "\n",
    "case_desc = np.array(['ERA5']+case_desc)\n",
    "#case_desc = np.array(['ERAI']+case_desc)\n",
    "#case_desc = np.array(['JRA25']+case_desc)\n",
    "\n",
    "case_type = np.array(['reanal']+case_type)\n",
    "\n",
    "\n",
    "case_desc = np.array(case_desc)\n",
    "case_type = np.array(case_type)\n",
    "reanal_climo = True # GRab climo. values for mean, Nino and nina events.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## INDIVIDUAL CASE SETTINGS/ADDITIONS ##\n",
    "\n",
    "''''' Which phase of enso to work with and the nino SST region '''''\n",
    "nino_region = 'nino34'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "''' SEASON '''\n",
    "\n",
    "seas_mons = np.array([\"Jan\",\"Feb\",\"Dec\"])\n",
    "\n",
    "clim_anal = False\n",
    "\n",
    "''''' Years for the analysis '''''\n",
    "\n",
    "years_data = (1989,2001) # Year range of history files to read AND either 'climo' one file or 'tseries' many files\n",
    "\n",
    "\n",
    "''' REGIONAL SPECS (LAT/LON/LEV) '''\n",
    "\n",
    "#lats_in = -10. ; latn_in = 5.\n",
    "#lonw_in = 150. ; lone_in = 220.\n",
    "ppmin = 50. ; ppmax = 1000.\n",
    "\n",
    "\n",
    "\n",
    "''''' Variable description '''''\n",
    "\n",
    "var_cam = 'U'\n",
    "ldiv = True # Calculate divergence from OMEGA\n",
    "\n",
    "''''' Directory Information '''''\n",
    "\n",
    "dir_croot = '/glade/p/cgd/amp/people/hannay/amwg/climo/' # Directories with climo files\n",
    "dir_hroot = '/glade/p/cgd/amp/amwg/runs/' # Run firectories with history files\n",
    "\n",
    "dir_proot = '/glade/u/home/rneale/python/python-figs/vert_proc/'\n",
    "dir_obs = '/glade/p/cesm/amwg/amwg_data/obs_data/'\n",
    "\n",
    "\n",
    "\n",
    "## Variables ##\n",
    "\n",
    "var_desc = {}\n",
    "\n",
    "var_desc['DTCOND'] = ['dT/dt Total',86400.,1., -5.,5.,'K/day']\n",
    "var_desc['DCQ']    = ['dq/dt Total',86400*1000.,1., -4.,4.,'g/kg/day']\n",
    "var_desc['ZMDT']   = ['dT/dt Convection',86400., 1.,-5.,5.,'K/day']\n",
    "var_desc['ZMDQ']   = ['dq/dt Convection',86400.*1000., 1.,-4.,4.,'g/kg/day']\n",
    "var_desc['STEND_CLUBB'] = ['dT/dt turbulence',86400./1004., 1. ,-2.,8.,'K/day']\n",
    "var_desc['OMEGA'] = ['OMEGA',-1., -100./86400., -0.004,0.004,'pa/s']\n",
    "var_desc['DIV'] = ['Divergence',1., 100./86400., -0.0004,0.0004,'s^-1']\n",
    "var_desc['T'] = ['Temperature',1., 1., -10.,10.,'K']\n",
    "var_desc['U'] = ['Zonal Wind',1., 1., -5.,5.,'m/s']\n",
    "\n",
    "''''' Named Regions '''''\n",
    "\n",
    "reg_names = {}\n",
    "\n",
    "\n",
    "#### RBN Original Locations ####\n",
    "reg_names['Nino Wet'] = ['C. Pacific Nino Wet',-10,0.,160.,210]  # Core of nino precip signal\n",
    "#reg_names['WP Dry']   = ['West Pac. Nino Dry.',-5.,10.,120.,150]  # Core of W. Pacific signal\n",
    "#reg_names['Conv U']   = ['Convergence Min',25,50.,160,190]       # Core of RWS convergence min.\n",
    "\n",
    "#### Anna Locations ####\n",
    "\n",
    "\n",
    "# Include observations? #\n",
    "lobs = False\n",
    "\n",
    "# Pressure info.\n",
    "\n",
    "p_levs = np.arange(ppmin,ppmax,50.)\n",
    "\n",
    "\n",
    "\n",
    "###### NAMES CATALOGUE ######\n",
    "#sim_names = cam_revert_list()\n",
    "#sim_names = cam_vres_list()\n",
    "#sim_names = mycase.cam_reanal_list()\n",
    "sim_names = mycase.mdtf_case_list()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Specify data frames ##\n",
    "\n",
    "reg_df = pd.DataFrame.from_dict(reg_names, orient='index',columns=['long_name','lat_s','lat_n','lon_w','lon_e'])\n",
    "var_df = pd.DataFrame.from_dict(var_desc, orient='index',columns=['long_name','vscale','ovscale','xmin','xmax','vunits'])\n",
    "\n",
    "display(reg_df)\n",
    "print()\n",
    "display(var_df)\n",
    "\n",
    "reg = list(reg_names.keys())[0]\n",
    "\n",
    "reg_s = reg_df.loc[reg]['lat_s'] ; reg_n = reg_df.loc[reg]['lat_n']\n",
    "reg_w = reg_df.loc[reg]['lon_w'] ; reg_e = reg_df.loc[reg]['lon_e']\n",
    "        \n",
    "print(reg_s)\n",
    "\n",
    "\n",
    "nmnths = seas_mons.size\n",
    "ncases = case_desc.size\n",
    "nregions = reg_df.index.size\n",
    "\n",
    "xmin = var_df.loc[var_cam]['xmin'] ; xmax=var_df.loc[var_cam]['xmax']\n",
    "vunits = var_df.loc[var_cam]['vunits'] \n",
    "var_text = var_df.loc[var_cam]['long_name']   \n",
    "\n",
    "if ldiv and var_cam == 'OMEGA':\n",
    "    var_pname = 'DIV'\n",
    "    var_text = var_df.loc[var_pname]['long_name']     \n",
    "    vunits = var_df.loc[var_pname]['vunits'] \n",
    "    xmin = var_df.loc[var_pname]['xmin'] ; xmax=var_df.loc[var_pname]['xmax']\n",
    "    \n",
    "\n",
    "#%matplotlib inline\n",
    "ds.config.set({\"array.slicing.split_large_chunks\": True})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENSO Phase Compositing of Tendencies \n",
    "- Read in hist timeseries\n",
    "- Calculate SST nino timeseries\n",
    "- Composites based on season for vertical profiles\n",
    "- Composites vertical profiles minus climo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "**** **** **** **** **** **** **** **** **** \n",
      "**** CASE #  [1]  OF  8  ****\n",
      "**** **** **** **** **** **** **** **** **** \n",
      "- Name =  ERA5  -> ERA5\n",
      "**** **** **** **** **** **** **** **** **** \n",
      "\n",
      "    -- File time type is climatological --\n",
      "['/glade/work/rneale/data/ERA5/ERA5_climo_DJF.nc'\n",
      " '/glade/work/rneale/data/ERA5/ERA5_nino_DJF.nc'\n",
      " '/glade/work/rneale/data/ERA5/ERA5_nino_DJF.nc']\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 721, lev: 32, lon: 1440, time: 3)\n",
      "Coordinates:\n",
      "  * lon      (lon) float64 0.0 0.25 0.5 0.75 1.0 ... 359.0 359.2 359.5 359.8\n",
      "  * lat      (lat) float64 -90.0 -89.75 -89.5 -89.25 ... 89.25 89.5 89.75 90.0\n",
      "  * lev      (lev) float64 1e+03 975.0 950.0 925.0 900.0 ... 50.0 30.0 20.0 10.0\n",
      "  * time     (time) float64 0.0 0.0 0.0\n",
      "Data variables:\n",
      "    u        (time, lev, lat, lon) float32 dask.array<chunksize=(1, 32, 721, 1440), meta=np.ndarray>\n",
      "    v        (time, lev, lat, lon) float32 dask.array<chunksize=(1, 32, 721, 1440), meta=np.ndarray>\n",
      "    hgt      (time, lev, lat, lon) float32 dask.array<chunksize=(1, 32, 721, 1440), meta=np.ndarray>\n",
      "Attributes:\n",
      "    CDI:          Climate Data Interface version ?? (http://mpimet.mpg.de/cdi)\n",
      "    Conventions:  CF-1.4\n",
      "    history:      Mon Aug 16 11:11:40 2021: cdo -f nc import_binary clima_DJF...\n",
      "    CDO:          Climate Data Operators version 1.7.0 (http://mpimet.mpg.de/...\n",
      "-- case_type files - type allowed\n",
      "    -- Grabbing data type/case -- reanal ERA5\n",
      "-- Grabbing SST file(s) for AMIP and REANALYSES from CESM inputdata -\n",
      "    -- PROCESSING FILE(S) ->>\n",
      "    --> First/Last ( 89  total number of files)\n",
      "/\n",
      "c\n",
      "<xarray.Dataset>\n",
      "Dimensions:            (lat: 192, lon: 288, time: 2064)\n",
      "Coordinates:\n",
      "  * lon                (lon) float64 0.0 1.25 2.5 3.75 ... 356.2 357.5 358.8\n",
      "  * lat                (lat) float64 -90.0 -89.06 -88.12 ... 88.12 89.06 90.0\n",
      "  * time               (time) object 1850-01-16 12:00:00 ... 2021-12-16 12:00:00\n",
      "Data variables:\n",
      "    date               (time) int32 dask.array<chunksize=(2064,), meta=np.ndarray>\n",
      "    datesec            (time) int32 dask.array<chunksize=(2064,), meta=np.ndarray>\n",
      "    ice_cov            (time, lat, lon) float32 dask.array<chunksize=(2064, 192, 288), meta=np.ndarray>\n",
      "    ice_cov_prediddle  (time, lat, lon) float32 dask.array<chunksize=(2064, 192, 288), meta=np.ndarray>\n",
      "    SST_cpl            (time, lat, lon) float32 dask.array<chunksize=(2064, 192, 288), meta=np.ndarray>\n",
      "    SST_cpl_prediddle  (time, lat, lon) float32 dask.array<chunksize=(2064, 192, 288), meta=np.ndarray>\n",
      "Attributes:\n",
      "    history:           N/A\n",
      "    data_mods:         N/A\n",
      "    climo_years:       1982-2001\n",
      "    data_reference:    Hurrell et al, 2008: A New Sea Surface Temperature and...\n",
      "    data_doi:          N/A\n",
      "    data_source_url:   via dennis shea ftp://ftp.cgd.ucar.edu/archive/SSTICE/\n",
      "    data_script:       regrid and bcgen under model tools\n",
      "    data_creator:      Julie Caron, jcaron@ucar.edu\n",
      "    cesm_contact:      Cecile Hannay, hannay@ucar.edu\n",
      "    data_description:  SST and ICE boundary dataset created from merged Reyno...\n",
      "    data_summary:      SST and ICE boundary dataset for CAM\n",
      "    creation_date:     Fri May 21 11:36:52 MDT 2021\n",
      "    -- FILE(S) AVAILABLE TIME RANGE - >  1850  to 2021\n",
      "\n",
      "Dataset required memory = 1826131968\n",
      "-- SET TIME RANGE OF TS DATA --  1989  to  2001\n",
      "-- Calculating and plotting nino SST anomalies\n",
      "    -- Calculating for SST anomalies  nino34  region\n",
      "First month is  <xarray.DataArray 'strftime' ()>\n",
      "array('Jan', dtype=object)\n",
      "Coordinates:\n",
      "    time     object 1989-01-16 12:00:00  not Jan: Exiting - should check it is not the h0 time stamp problem if CAM data\n",
      "    -- Removing SST Annual Cycles --\n",
      "    -- Plotting SST anomalies timeseries --\n",
      "-- NINO grab:  Done --\n",
      "\n",
      "-- Region =  C. Pacific Nino Wet  -  -10 0.0 160.0 210\n",
      "-- Averaging for region -  160-210Â°E -10.0-0Â°N\n",
      "    -- Period = Climatology (1989-2001)\n",
      "    -- Period = El Nino\n",
      "    -- Period = La Nina\n",
      "\n",
      "\n",
      "\n",
      "**** **** **** **** **** **** **** **** **** \n",
      "**** CASE #  [2]  OF  8  ****\n",
      "**** **** **** **** **** **** **** **** **** \n",
      "- Name =  C6  -> f.e20.FHIST.f09_f09.cesm2_1.001\n",
      "**** **** **** **** **** **** **** **** **** \n",
      "\n",
      "-- case_type files - type allowed\n",
      "    -- Grabbing data type/case -- cam6_revert f.e20.FHIST.f09_f09.cesm2_1.001\n",
      "    -- Grabbing file(s) for CAM6 revert experiment - Variable =  U\n",
      "    -- PROCESSING FILE(S) ->>\n",
      "    --> First/Last ( 156  total number of files)\n",
      "/glade/p/cgd/amp/amwg/runs/f.e20.FHIST.f09_f09.cesm2_1.001/atm/hist/f.e20.FHIST.f09_f09.cesm2_1.001.cam.h0.1989-01.nc\n",
      "/glade/p/cgd/amp/amwg/runs/f.e20.FHIST.f09_f09.cesm2_1.001/atm/hist/f.e20.FHIST.f09_f09.cesm2_1.001.cam.h0.2001-12.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/rneale/python/miniconda3/envs/neale_myenv/lib/python3.8/site-packages/xarray/backends/plugins.py:107: RuntimeWarning: 'netcdf4' fails while guessing\n",
      "/glade/work/rneale/python/miniconda3/envs/neale_myenv/lib/python3.8/site-packages/xarray/backends/plugins.py:107: RuntimeWarning: 'scipy' fails while guessing\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "did not find a match in any of xarray's currently installed IO backends ['netcdf4', 'scipy', 'cfgrib']. Consider explicitly selecting one of the installed backends via the ``engine`` parameter to xarray.open_dataset(), or installing additional IO dependencies:\nhttp://xarray.pydata.org/en/stable/getting-started-guide/installing.html\nhttp://xarray.pydata.org/en/stable/user-guide/io.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/python/python-scripts/vert_proc/vert_prof_func.py\u001b[0m in \u001b[0;36mget_files_tseries\u001b[0;34m(case_name, case_type, var_cam, years)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;31m## POINT TO FILES ##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m     \u001b[0mdata_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_mfdataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles_glade\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_cf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_times\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 3 mins ERA5: 1979-1990\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/rneale/python/miniconda3/envs/neale_myenv/lib/python3.8/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mopen_mfdataset\u001b[0;34m(paths, chunks, concat_dim, compat, preprocess, engine, data_vars, coords, combine, parallel, join, attrs_file, combine_attrs, **kwargs)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[0mgetattr_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mopen_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0mclosers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_close\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mds\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpreprocess\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/rneale/python/miniconda3/envs/neale_myenv/lib/python3.8/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[0mgetattr_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mopen_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0mclosers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_close\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mds\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpreprocess\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/rneale/python/miniconda3/envs/neale_myenv/lib/python3.8/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, backend_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m         \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguess_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/rneale/python/miniconda3/envs/neale_myenv/lib/python3.8/site-packages/xarray/backends/plugins.py\u001b[0m in \u001b[0;36mguess_engine\u001b[0;34m(store_spec)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0minstalled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mengines\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"store\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minstalled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0;34m\"did not find a match in any of xarray's currently installed IO \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;34mf\"backends {installed}. Consider explicitly selecting one of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: did not find a match in any of xarray's currently installed IO backends ['netcdf4', 'scipy', 'cfgrib']. Consider explicitly selecting one of the installed backends via the ``engine`` parameter to xarray.open_dataset(), or installing additional IO dependencies:\nhttp://xarray.pydata.org/en/stable/getting-started-guide/installing.html\nhttp://xarray.pydata.org/en/stable/user-guide/io.html"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "importlib.reload(mypy) # Required because I am constantly editing scam_func.py\n",
    "importlib.reload(mycase) # Required because I am constantly editing scam_func.py\n",
    "\n",
    "\n",
    "\n",
    "# importlib.reload(mypy) # Required because I am constantly editing scam_func.py\n",
    "\n",
    "### Read in history monthly mean files and composite profiles for tendencies###\n",
    "dir_hroot = '/glade/p/cgd/amp/amwg/runs/'\n",
    "\n",
    "#### Read in Data ####\n",
    "\n",
    "yr0 = years_data[0]\n",
    "yr1 = years_data[1]\n",
    "\n",
    "\n",
    "nino_names = ['Climatology ('+str(yr0)+'-'+str(yr1)+')','El Nino','La Nina']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  ## PLOTTING RESOURCES\n",
    "\n",
    "fign, axn = mp.subplots(1,3,figsize=(26, 11))  \n",
    "\n",
    "nino_colors = ['black','red','blue']\n",
    "\n",
    "'''\n",
    "########################\n",
    "##### LOOP CASES  ######\n",
    "########################\n",
    "'''\n",
    "\n",
    "\n",
    "for icase,case in enumerate(case_desc): # Do first so don't have to do a read mutliple times\n",
    "\n",
    "# Grab run name \n",
    "    \n",
    "    sim_name = sim_names.loc[case]['run name']\n",
    "    \n",
    "    lclimo = True if reanal_climo and case_type[icase] == 'reanal' else False\n",
    "   \n",
    "    \n",
    "    print('')\n",
    "    print('')\n",
    "    print('')\n",
    "    print('**** **** **** **** **** **** **** **** **** ')\n",
    "    print('**** CASE # ',[icase+1],' OF ',ncases,' ****')\n",
    "    print('**** **** **** **** **** **** **** **** **** ')\n",
    "    print('- Name = ',case,' ->',sim_name)\n",
    "    print('**** **** **** **** **** **** **** **** **** ')\n",
    "    print('')   \n",
    "        \n",
    "        \n",
    "## Read data in from files ##\n",
    "\n",
    "# Construct required history file month-year array\n",
    "\n",
    "#    hist_myr = np.array([\".cam.h0.%d-%02d.nc\"%(y, m) for y in range(yr0,yr1+1) for m in range(1,12+1)])\n",
    "#    num_h0 = hist_myr.size\n",
    "  \n",
    "\n",
    "#    hfile_var = get_files_tseries(run_type,case_type,True) # Grab SST files\n",
    "   \n",
    "    \n",
    "    if lclimo:  # Read in tseries based files here for the analysis variable\n",
    "        files_ptr,var_name   = mypy.get_files_climo(sim_name,case_type[icase],var_cam,years_data) # Grab variable\n",
    "    else :\n",
    "        files_ptr,var_name   = mypy.get_files_tseries(sim_name,case_type[icase],var_cam,years_data) # Grab variable\n",
    "    \n",
    "    \n",
    "   \n",
    "## TS FROM HISTORY FILES (just copy for h0 files if they are already read in)\n",
    "## Can still do this for lclimo as it will take observed if reanal\n",
    "\n",
    "    if case_type[icase] in ['cam6_revert']: # I think this effectively acts as a pointer, I hope!\n",
    "        tfiles_ptr = files_ptr \n",
    "        tvar_name = 'TS'\n",
    "    else :   \n",
    "        tfiles_ptr,tvar_name = mypy.get_files_tseries(sim_name,case_type[icase],'TS',years_data) # Grab TS for nino timeseries\n",
    "\n",
    "\n",
    "# Have to modify based on month 1 is jan and not feb\n",
    "#    hfiles_ptr.time.dt.month[0]=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#    hmonths = hfiles_ptr.time.dt.month    \n",
    "\n",
    "    ''' TRIM FOR SPECIFIED YEARS '''\n",
    "    \n",
    "    print('-- SET TIME RANGE OF TS DATA -- ',yr0,' to ',yr1)\n",
    "    print('-- Calculating and plotting nino SST anomalies')\n",
    "    \n",
    "    sst_data = tfiles_ptr[tvar_name].sel(time=slice(str(yr0), str(yr1)))\n",
    "   \n",
    "    \n",
    "    ''' SST ANOMALY ROUTINE ARRAY '''\n",
    "  \n",
    "    sst_months =  sst_data.time.dt.strftime(\"%b\")    \n",
    "    inino_mons,inina_mons = mypy.nino_sst_anom(sim_name,sst_data,nino_region)\n",
    "    \n",
    "    print('-- NINO grab:  Done --')\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    ''' SUBSET SEASON MONTHS '''\n",
    "    \n",
    "#    print(files_ptr[var_name].dt)     \n",
    "#    date_after_month = date.today()+ relativedelta(months=1)\n",
    "#    print ('Today: ',date.today().strftime('%d/%m/%Y'))\n",
    "#    print ('After Month:', dt.strftime('%d/%m/%Y'))\n",
    "\n",
    "#    dt_index = files_ptr.indexes['time'].to_datetimeindex()\n",
    "#    print(dt.date.today())\n",
    "#    print(dt_index.month)\n",
    "#    print(relativedelta(months=-1))\n",
    "#    print(dt.date.today()+relativedelta(months=-10))\n",
    "\n",
    "#    print(dt_index+relativedelta(months=+1))\n",
    "\n",
    "#    print(dt_index.month)\n",
    "    \n",
    "    \n",
    "#    time = files_ptr.time \n",
    "#    print(dt_index)\n",
    "#    files_ptr['time'] = dt_index \n",
    "    \n",
    "#    hmonths = files_ptr.time.dt.strftime(\"%b\")\n",
    " \n",
    "#    print(files_ptr.time.time)\n",
    "#    print(pd.to_datetime(files_ptr.time))\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    " \n",
    "   \n",
    "        \n",
    "# Just read in the season months and levs we need\n",
    "    \n",
    "   \n",
    "    if not lclimo:\n",
    "        \n",
    "        ## Need to split what is done fo climo versus tseries here.\n",
    "\n",
    "        \n",
    "        var_in = files_ptr[var_name].sel(time=slice(str(yr0),str(yr1)))\n",
    "        \n",
    "\n",
    "        if case_type[icase] in ['lens1','lens2']:\n",
    "            print('-- \"Compute\" the variable array now (bring it up from lazy array) if != ANALYSES')\n",
    "            %time var_in = var_in.compute()\n",
    "\n",
    "    # Grab time coord.\n",
    "        time_in = var_in.time\n",
    "\n",
    "\n",
    "        ''' Need to rename Vertical Pressure Coordinate '''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ''' Trim locations (lat/lev) for simplicity '''\n",
    "\n",
    "\n",
    "        lev_in = var_in.lev\n",
    "\n",
    "        ilevs = np.where(lev_in >= min(p_levs))\n",
    "\n",
    "        ilevs = ilevs[0]\n",
    "        lev = lev_in[ilevs]\n",
    "\n",
    "\n",
    "    # Check SST size with Variable size\n",
    "\n",
    "        if sst_data.time.size != time_in.size : print('SST and VARIABLE sizes DO NOT MATCH - ',sst_data.time.size,' and ',time_in.size) \n",
    "\n",
    "        month_nums = time_in.dt.month   \n",
    "        hmonths = time_in.dt.strftime(\"%b\")\n",
    "\n",
    "\n",
    "\n",
    "    # Poor man's modifcation for lens1 ts\n",
    "    #    if case_type[icase] == 'lens1' :\n",
    "    #            month_nums = month_nums-1 # Set back 1 month\n",
    "    #            month_nums[month_nums ==-1] = 12 # Set -1 months back to 12\n",
    "    #    mon_obj = dt.datetime.strptime(mon_nums, \"%m\")\n",
    "\n",
    "\n",
    "        lmon_seas = np.isin(hmonths,seas_mons) # Logical for seaon months in all months\n",
    "        imon_seas = np.argwhere(lmon_seas)[:,0] # Indices\n",
    "        hmon_seas = hmonths[imon_seas] # Subsetting full months.\n",
    "\n",
    "\n",
    "    # Seasonal selection for ninos \n",
    "\n",
    "    #    lnino_seas = np.isin(hmonths[inino_mons],seas_mons) # Logical for season months in all months\n",
    "    #    inino_seas= inino_mons[np.argwhere(lnino_seas)[:,0]] # Indices of origin nino_mons that match the season\n",
    "    #    inino_seas = np.argwhere(lnino_seas)[:,0] # Indices of origin nino_mons that match the season\n",
    "\n",
    "\n",
    "    #    lnina_seas = np.isin(hmonths[inina_mons],seas_mons) # Logical for season months in all months\n",
    "    #    inina_seas= inina_mons[np.argwhere(lnina_seas)[:,0]] # Indices of origin nino_mons that match the season\n",
    "    #    inina_seas= np.argwhere(lnina_seas)[:,0] # Indices of origin nino_mons that match the season   \n",
    "\n",
    "        var_in = var_in.loc[:,:,reg_s:reg_n,reg_w:reg_e] # Limit the levels\n",
    "\n",
    "    #  \n",
    "        var_in = var_in[:,ilevs,:,:]   \n",
    "        dp_lev = np.diff(lev)\n",
    "\n",
    "\n",
    "\n",
    "    ## Much easier than above but doing the intersections of months and nino months.\n",
    "        inino_seas,inino_ind,imon_nino_ind = np.intersect1d(inino_mons, imon_seas, return_indices=True)\n",
    "        inina_seas,inina_ind,imon_nina_ind = np.intersect1d(inina_mons, imon_seas, return_indices=True)\n",
    "\n",
    "\n",
    "    ## Could speed up below by reading in var_in for the season months then subsetting that for nino/nina    \n",
    "    ## Remember: It is reading in a subset of seaonal months and then nino/nina are a subset of those. \n",
    "\n",
    "        var_in_inseas = var_df.loc[var_cam]['vscale']*var_in[imon_seas,:,:,:] # Pull only the months we need\n",
    "\n",
    "\n",
    "        if case_type[icase] in ['reanal','cam6_revert']:\n",
    "            print('-- \"Compute\" the variable array now (bring it up front lazy array) if == ANALYSES')\n",
    "            %time var_in_inseas = var_in_inseas.compute()\n",
    "\n",
    "        var_in_seas = var_in_inseas.mean(dim=['time'])  # Perform seasonal average\n",
    "\n",
    "        var_in_nino = var_in_inseas[imon_nino_ind,:,:,:].mean(dim=['time'])  # Take nino/nina months from the seasonal timeseries months\n",
    "        var_in_nina = var_in_inseas[imon_nina_ind,:,:,:].mean(dim=['time']) \n",
    "\n",
    "    \n",
    "    else :    ### Just grab separate data from climo, nino and nina files.\n",
    "        \n",
    "        var_in_seas =  files_ptr[var_name].isel(time=0)\n",
    "        var_in_nino =  files_ptr[var_name].isel(time=1)\n",
    "        var_in_nina =  files_ptr[var_name].isel(time=2)\n",
    "        \n",
    "        \n",
    "        lev_in = var_in_seas.lev\n",
    "        ilevs = np.where(lev_in >= min(p_levs))\n",
    "\n",
    "        lev = lev_in[ilevs]\n",
    "\n",
    "\n",
    "        var_in_seas =  var_in_seas.loc[lev[0]:lev[-1],reg_s:reg_n,reg_w:reg_e]\n",
    "        var_in_nino =  var_in_nino.loc[lev[0]:lev[-1],reg_s:reg_n,reg_w:reg_e]\n",
    "        var_in_nina =  var_in_nina.loc[lev[0]:lev[-1],reg_s:reg_n,reg_w:reg_e]\n",
    "\n",
    "    \n",
    "## USUAL WAY ##    \n",
    "    \n",
    "#    var_in_seas = var_df.loc[var_cam]['vscale']*var_in[imon_seas,:,:,:].mean(dim=['time']) \n",
    "#    var_in_nino = var_df.loc[var_cam]['vscale']*var_in[inino_seas,:,:,:].mean(dim=['time']) \n",
    "#    var_in_nina = var_df.loc[var_cam]['vscale']*var_in[inina_seas,:,:,:].mean(dim=['time']) \n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "    ########################    \n",
    "    ### Now Loop Regions ###\n",
    "    ########################\n",
    "    ''' \n",
    "    \n",
    "    for ireg,reg in enumerate(reg_df.index):  ## 4 regions let's assume ##\n",
    "\n",
    "### Assign lat/lon region domain ###\n",
    "\n",
    "        reg_name = reg_df.loc[reg]['long_name'] \n",
    "    \n",
    "#        reg_s = reg_df.loc[reg]['lat_s'] ; reg_n = reg_df.loc[reg]['lat_n']\n",
    "#        reg_w = reg_df.loc[reg]['lon_w'] ; reg_e = reg_df.loc[reg]['lon_e']\n",
    "        \n",
    "        print()\n",
    "        print('-- Region = ',reg_name,' - ',reg_s,reg_n,reg_w,reg_e)\n",
    "                   \n",
    "        reg_a_str = '%d-%d\\u00b0E %.1f-%d\\u00b0N' % (reg_w,reg_e,reg_s,reg_n)\n",
    "        reg_a_out = '%d-%dE_%.1f-%dN' % (reg_w,reg_e,reg_s,reg_n)  \n",
    "         \n",
    "        print('-- Averaging for region - ',reg_a_str)\n",
    "\n",
    "        \n",
    "        \n",
    "### Compute Seasonal/El Nino/La Nina profiles\n",
    "         \n",
    "\n",
    "    \n",
    "        varp_seas = var_in_seas.loc[:,reg_s:reg_n,reg_w:reg_e]\n",
    "        varp_nino = var_in_nino.loc[:,reg_s:reg_n,reg_w:reg_e]-varp_seas\n",
    "        varp_nina = var_in_nina.loc[:,reg_s:reg_n,reg_w:reg_e]-varp_seas\n",
    "        \n",
    "        varp_all = (varp_seas,varp_nino,varp_nina) # Put in tuple for looping.\n",
    "               \n",
    "        \n",
    "        \n",
    "        pmark,lcolor,lwidth  = ('x','black',3)   if case_type[icase] == 'reanal' else   ('.','red',1)  \n",
    "        if case_type[icase] == 'cam6_revert':\n",
    "            pmark,lcolor,lwidth = ('.',None,1)\n",
    "    \n",
    "              \n",
    "                           \n",
    "        '''\n",
    "        ####################################    \n",
    "        ### Loop climo/nino/nina periods ###\n",
    "        ####################################\n",
    "        '''     \n",
    "        \n",
    "## LOOP: Seasonal/El Nino/La Nina plots for this region.\n",
    " \n",
    "\n",
    "        for iplot,var_plot in enumerate(varp_all):\n",
    "            \n",
    "            print('    -- Period = '+nino_names[iplot])\n",
    "\n",
    "# Regional average\n",
    "            var_fig = var_plot.mean(dim=['lat','lon'],skipna = True)   \n",
    "        \n",
    "        \n",
    "           \n",
    "            \n",
    "            if ldiv and var_cam == 'OMEGA':\n",
    "                var_fig = var_fig.differentiate(\"lev\")\n",
    "                \n",
    "            axn[iplot].plot(var_fig,lev,lw=lwidth,markersize=9,marker=pmark,color=lcolor)  \n",
    " \n",
    "\n",
    "\n",
    "            if (icase==0) :\n",
    "                axn[iplot].set_title(nino_names[iplot],fontsize=20,color=nino_colors[iplot])\n",
    "                axn[iplot].set_xlim([xmin,xmax])\n",
    "                axn[iplot].set_ylim([ppmax,ppmin])\n",
    "                axn[iplot].set_ylabel('mb',fontsize=20) \n",
    "                axn[iplot].set_xlabel(vunits,fontsize=20)      \n",
    "                axn[iplot].set_yticks(p_levs)\n",
    "                axn[iplot].set_yticklabels(p_levs,fontsize=15)\n",
    "            \n",
    "                axn[iplot].grid(linestyle='--')  \n",
    "              \n",
    "#               if ((xmin < 0) and (xmax > 0)) :\n",
    "                axn[iplot].vlines(0., ppmax, ppmin, linestyle=\"--\",lw=3, color='black')\n",
    "\n",
    "             \n",
    "    \n",
    "# Legend ### Perform a bit of logic for the  \n",
    "#rtypes, counts = np.unique(case_type, return_counts=True)\n",
    "#if counts.min == 1:\n",
    "leg_cases = case_desc\n",
    "\n",
    "# Don't repeat lens in legend if there are many cases.\n",
    "if 'lens1' in case_type : \n",
    "    leg_cases = [case_desc[0],'lens1']\n",
    "    if 'reanal' not in case_type :\n",
    "        leg_cases = ['lens1']\n",
    "        \n",
    "if 'lens2' in case_type : \n",
    "    leg_cases = [case_type[0],'lens2']\n",
    "    if 'reanal' not in case_type :\n",
    "        leg_cases = ['lens2']\n",
    "    \n",
    "\n",
    "lloc = 'lower right' if var_name in ['ZMDQ','STEND_CLUBB'] else 'lower left' \n",
    "axn[0].legend(leg_cases,fontsize=15,loc = lloc)\n",
    "\n",
    "\n",
    "    # Main title\n",
    "fign.suptitle('ENSO Anomalies - '+reg_name+' -- '+reg_a_str+' - '+var_text,fontsize=20)\n",
    "\n",
    "mp.rcParams['xtick.labelsize'] = 15 # Global set of xtick label size    \n",
    "\n",
    "    \n",
    "#    mp.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Hard copy  \n",
    "fign.savefig(dir_proot+pref_out+'_nino_vprof_'+var_name+'_'+reg_a_out+'_'+str(yr0)+'_to_'+str(yr1)+'.png', dpi=80)\n",
    "\n",
    "#mp.show()   |\n",
    "\n",
    "print()\n",
    "print()\n",
    "print('-- End Timing --')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:neale_myenv]",
   "language": "python",
   "name": "conda-env-neale_myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
